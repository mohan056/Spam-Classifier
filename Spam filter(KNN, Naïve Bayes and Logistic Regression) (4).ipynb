{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/abhirajmohan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score as acc\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import statsmodels.api as sm\n",
    "from imblearn.over_sampling import SMOTE as smote\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     v1                                                 v2 Unnamed: 2  \\\n",
      "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
      "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
      "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
      "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
      "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
      "\n",
      "  Unnamed: 3 Unnamed: 4  \n",
      "0        NaN        NaN  \n",
      "1        NaN        NaN  \n",
      "2        NaN        NaN  \n",
      "3        NaN        NaN  \n",
      "4        NaN        NaN  \n"
     ]
    }
   ],
   "source": [
    "corpus_data = pd.read_csv(\"spam.csv\", encoding='latin-1')\n",
    "print(corpus_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After printing out the first five rows of our data set, we observe that the last three columns of the data set have unrecognizable values which cannot be used to train our models since they will not provide any important information. We also observe that each message has various stopwords that can be removed. This is believable considering how casual people are with their language when messaging each other. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set we wish to use contains 5572 rows which mean 5572 records. These many rows are more than enough to trian our models with. We will explore the class imbalance in our models in later on sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['v1', 'v2', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_data.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of these columns, we care only about v1 and v2. The last three columns we do not care about and will remove."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "After we explore in our data set, there are significant changes we need to make to our data set before we can train our classifier models using this data. First, since we noticed that the last three columns of our data set are useless to training our model, we remove those columns. We do this so that training our models is more optimal run-time wise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_data = corpus_data.drop([\"Unnamed: 2\",\"Unnamed: 3\", \"Unnamed: 4\"], axis=1)\n",
    "corpus_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing stopwords and punctuations\n",
    "In Natural Language Processing, a common practice is to remove stopwords and punctuations. Stopwords are common words that are present in almost every text such as \"a, this, the\", etc. We remove these words from our records since they do not provide models any significant information about each text. Along with that, we need to remove punctuation to be able to construct a TF-IDF matrix out of our data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sample message let us see happens sample meassage'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_stopwords(sentence):\n",
    "    sentence = sentence.split(' ')\n",
    "    processed_sentence = []\n",
    "    for word in sentence:\n",
    "        no_pun = [char for char in word if char not in string.punctuation]\n",
    "        no_pun = ''.join(no_pun)\n",
    "        processed_sentence.append(no_pun)\n",
    "    processed = [word.lower() for word in processed_sentence if word.lower() not in stopwords.words('english')]\n",
    "    processed = ' '.join(processed)\n",
    "    return processed\n",
    "    \n",
    "stringing = \"This is a sample message. Let us see what happens sample meassage\"\n",
    "remove_stopwords(stringing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code block above, we have defined a function to  remove stop-words and punctuation. Something that we do not do in this section but is extremely common is the practice of stemming text. This is the process of reducing words to their most basic version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_data[\"v2\"] = corpus_data['v2'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code block, we apply the filter function to remove stopwords and punctuations to reduce our data set to processable string of significant words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating TF-IDF Matrix\n",
    "(https://www.elephate.com/blog/what-is-tf-idf/)  \n",
    "After we have removed all the stopwords and punctuations from each text in the data set, we now have a data set that we can use to build our TF-IDF matrix. We use TF-IDF algorithm to convert our textual data set into a numerical data set.\n",
    "TF-IDF translates to Term-frequency Inverse-document-frequency which is an algorithm to process text documents. The algorithm takes the word composition of each document and finds the term frequency of each word in the text which the number of times a term occurs in a text. And we calculate the inverse document frequency of a term which is the measure of how much information the term provides which is caluclated as the logarithmic function of the total documents divided by the number of documents that have an occurence of that word. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "corpus_tf_idf = vectorizer.fit_transform(corpus_data[\"v2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We call TfidfVectorizer on our data set with an ngram range of (1,1). An ngram range of 1,1 means that our tf-idf matrix will have 1grams as minimum and maximum. In a later iteration of our project, we can vary the ngram range to observe how it change the performance of classifier models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_scores = pd.DataFrame(corpus_tf_idf.todense())\n",
    "tf_idf_scores.columns = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 9376)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus_data_11 = corpus_data\n",
    "# corpus_data_12 = corpus_data\n",
    "countr = 0\n",
    "for i in vectorizer.get_feature_names():\n",
    "    corpus_data[i] = tf_idf_scores[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>008704050406</th>\n",
       "      <th>0089my</th>\n",
       "      <th>0121</th>\n",
       "      <th>01223585236</th>\n",
       "      <th>01223585334</th>\n",
       "      <th>0125698789</th>\n",
       "      <th>02</th>\n",
       "      <th>020603</th>\n",
       "      <th>...</th>\n",
       "      <th>ìï</th>\n",
       "      <th>ìïll</th>\n",
       "      <th>ûthanks</th>\n",
       "      <th>ûªm</th>\n",
       "      <th>ûªt</th>\n",
       "      <th>ûªve</th>\n",
       "      <th>ûï</th>\n",
       "      <th>ûïharry</th>\n",
       "      <th>ûò</th>\n",
       "      <th>ûówell</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>go jurong point crazy available bugis n great ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>free entry 2 wkly comp win fa cup final tkts 2...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>u dun say early hor u c already say</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>nah dont think goes usf lives around though</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 9378 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2  008704050406  \\\n",
       "0   ham  go jurong point crazy available bugis n great ...           0.0   \n",
       "1   ham                            ok lar joking wif u oni           0.0   \n",
       "2  spam  free entry 2 wkly comp win fa cup final tkts 2...           0.0   \n",
       "3   ham                u dun say early hor u c already say           0.0   \n",
       "4   ham        nah dont think goes usf lives around though           0.0   \n",
       "\n",
       "   0089my  0121  01223585236  01223585334  0125698789   02  020603   ...    \\\n",
       "0     0.0   0.0          0.0          0.0         0.0  0.0     0.0   ...     \n",
       "1     0.0   0.0          0.0          0.0         0.0  0.0     0.0   ...     \n",
       "2     0.0   0.0          0.0          0.0         0.0  0.0     0.0   ...     \n",
       "3     0.0   0.0          0.0          0.0         0.0  0.0     0.0   ...     \n",
       "4     0.0   0.0          0.0          0.0         0.0  0.0     0.0   ...     \n",
       "\n",
       "    ìï  ìïll  ûthanks  ûªm  ûªt  ûªve   ûï  ûïharry   ûò  ûówell  \n",
       "0  0.0   0.0      0.0  0.0  0.0   0.0  0.0      0.0  0.0     0.0  \n",
       "1  0.0   0.0      0.0  0.0  0.0   0.0  0.0      0.0  0.0     0.0  \n",
       "2  0.0   0.0      0.0  0.0  0.0   0.0  0.0      0.0  0.0     0.0  \n",
       "3  0.0   0.0      0.0  0.0  0.0   0.0  0.0      0.0  0.0     0.0  \n",
       "4  0.0   0.0      0.0  0.0  0.0   0.0  0.0      0.0  0.0     0.0  \n",
       "\n",
       "[5 rows x 9378 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After converting our matrix to a Tf-idf matrix, we see that our matrix is extremely sparse because of the high occurence of 0 values. This is characteristic of a Tf-idf matrix since some terms out of the whole corpus will never be part of some texts.\n",
    "\n",
    "After converting our text data set into a TF-IDF, we can check for null values as a sanity check to make sure we did not lose any information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values = 0\n"
     ]
    }
   ],
   "source": [
    "df_is_na = corpus_data.isna()\n",
    "no_missing_values = 0\n",
    "for index, row in df_is_na.iterrows():\n",
    "    if(row[1]):\n",
    "        no_missing_values += 1\n",
    "print(\"Number of missing values =\",no_missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number fo null values in our tf-idf matrix our 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>008704050406</th>\n",
       "      <th>0089my</th>\n",
       "      <th>0121</th>\n",
       "      <th>01223585236</th>\n",
       "      <th>01223585334</th>\n",
       "      <th>0125698789</th>\n",
       "      <th>02</th>\n",
       "      <th>020603</th>\n",
       "      <th>0207</th>\n",
       "      <th>...</th>\n",
       "      <th>ìï</th>\n",
       "      <th>ìïll</th>\n",
       "      <th>ûthanks</th>\n",
       "      <th>ûªm</th>\n",
       "      <th>ûªt</th>\n",
       "      <th>ûªve</th>\n",
       "      <th>ûï</th>\n",
       "      <th>ûïharry</th>\n",
       "      <th>ûò</th>\n",
       "      <th>ûówell</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 9377 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1  008704050406  0089my  0121  01223585236  01223585334  0125698789  \\\n",
       "0   ham           0.0     0.0   0.0          0.0          0.0         0.0   \n",
       "1   ham           0.0     0.0   0.0          0.0          0.0         0.0   \n",
       "2  spam           0.0     0.0   0.0          0.0          0.0         0.0   \n",
       "3   ham           0.0     0.0   0.0          0.0          0.0         0.0   \n",
       "4   ham           0.0     0.0   0.0          0.0          0.0         0.0   \n",
       "\n",
       "    02  020603  0207   ...     ìï  ìïll  ûthanks  ûªm  ûªt  ûªve   ûï  \\\n",
       "0  0.0     0.0   0.0   ...    0.0   0.0      0.0  0.0  0.0   0.0  0.0   \n",
       "1  0.0     0.0   0.0   ...    0.0   0.0      0.0  0.0  0.0   0.0  0.0   \n",
       "2  0.0     0.0   0.0   ...    0.0   0.0      0.0  0.0  0.0   0.0  0.0   \n",
       "3  0.0     0.0   0.0   ...    0.0   0.0      0.0  0.0  0.0   0.0  0.0   \n",
       "4  0.0     0.0   0.0   ...    0.0   0.0      0.0  0.0  0.0   0.0  0.0   \n",
       "\n",
       "   ûïharry   ûò  ûówell  \n",
       "0      0.0  0.0     0.0  \n",
       "1      0.0  0.0     0.0  \n",
       "2      0.0  0.0     0.0  \n",
       "3      0.0  0.0     0.0  \n",
       "4      0.0  0.0     0.0  \n",
       "\n",
       "[5 rows x 9377 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_data = corpus_data.drop(\"v2\", axis=1)\n",
    "corpus_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 9377)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as we can see, our data set maintains the number of rows. Thus, we retain all the information throughout all the pre-processing.\n",
    "\n",
    "We now proceed to split our data into training and test data sets in the ratio of 8 is to 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = corpus_data.drop(\"v1\", axis=1)\n",
    "training_corpus, test_corpus, training_label, test_label = train_test_split(corpus, corpus_data[\"v1\"], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1115, 9376)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_corpus.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Class Imbalance\n",
    "For our purposes, we wish to train our models to the best capacity. Thus, we explore our data sets to see if there is a class imbalance. Unchecked class imbalance causes a bias towards the majority class when we run our models to classify and predict test sets.\n",
    "\n",
    "To explore class imbalance, we visualize the two classes in our data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'number of records')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "count_of_ham = training_corpus[training_label == \"ham\"].shape[0]\n",
    "count_of_spam = training_corpus[training_label == \"spam\"].shape[0]\n",
    "plt.bar([\"Ham\", \"Spam\"], height=[count_of_ham, count_of_spam])\n",
    "plt.ylabel(\"number of records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that there is a clear difference in the number of records that are spam and that are ham in our data set. To deal with this problem, we will run SMOTE on our data set. Synthetic Minority Over-Sampling Technique or SMOTE simulatneously overs-samples the minority class and under-samples the majority class (https://jair.org/index.php/jair/article/view/10302). We run this algorithm on our training data set to obtain the same class count for both the classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sml = smote(random_state=12)\n",
    "X, y = sml.fit_sample(training_corpus, training_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Number of records')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = pd.DataFrame(X)\n",
    "X.columns = training_corpus.columns\n",
    "y = pd.DataFrame(y)\n",
    "count_of_ham = y[y[0] == \"ham\"].shape[0]\n",
    "count_of_spam = y[y[0] == \"spam\"].shape[0]\n",
    "plt.bar([\"Ham\", \"Spam\"], height=[count_of_ham, count_of_spam])\n",
    "plt.ylabel(\"Number of records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running SMOTE on our data-set, we can observe that the count of ham in our data set and count of spam is the same. We will retain our unbalanced data as well, however, to observe how balancing classes affects the performance of our classifier models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>008704050406</th>\n",
       "      <th>0089my</th>\n",
       "      <th>0121</th>\n",
       "      <th>01223585236</th>\n",
       "      <th>01223585334</th>\n",
       "      <th>0125698789</th>\n",
       "      <th>02</th>\n",
       "      <th>020603</th>\n",
       "      <th>0207</th>\n",
       "      <th>02070836089</th>\n",
       "      <th>...</th>\n",
       "      <th>ìï</th>\n",
       "      <th>ìïll</th>\n",
       "      <th>ûthanks</th>\n",
       "      <th>ûªm</th>\n",
       "      <th>ûªt</th>\n",
       "      <th>ûªve</th>\n",
       "      <th>ûï</th>\n",
       "      <th>ûïharry</th>\n",
       "      <th>ûò</th>\n",
       "      <th>ûówell</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4359</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2431</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1321</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1410</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 9376 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      008704050406  0089my  0121  01223585236  01223585334  0125698789   02  \\\n",
       "4359           0.0     0.0   0.0          0.0          0.0         0.0  0.0   \n",
       "2431           0.0     0.0   0.0          0.0          0.0         0.0  0.0   \n",
       "1321           0.0     0.0   0.0          0.0          0.0         0.0  0.0   \n",
       "1410           0.0     0.0   0.0          0.0          0.0         0.0  0.0   \n",
       "79             0.0     0.0   0.0          0.0          0.0         0.0  0.0   \n",
       "\n",
       "      020603  0207  02070836089   ...     ìï  ìïll  ûthanks  ûªm  ûªt  ûªve  \\\n",
       "4359     0.0   0.0          0.0   ...    0.0   0.0      0.0  0.0  0.0   0.0   \n",
       "2431     0.0   0.0          0.0   ...    0.0   0.0      0.0  0.0  0.0   0.0   \n",
       "1321     0.0   0.0          0.0   ...    0.0   0.0      0.0  0.0  0.0   0.0   \n",
       "1410     0.0   0.0          0.0   ...    0.0   0.0      0.0  0.0  0.0   0.0   \n",
       "79       0.0   0.0          0.0   ...    0.0   0.0      0.0  0.0  0.0   0.0   \n",
       "\n",
       "       ûï  ûïharry   ûò  ûówell  \n",
       "4359  0.0      0.0  0.0     0.0  \n",
       "2431  0.0      0.0  0.0     0.0  \n",
       "1321  0.0      0.0  0.0     0.0  \n",
       "1410  0.0      0.0  0.0     0.0  \n",
       "79    0.0      0.0  0.0     0.0  \n",
       "\n",
       "[5 rows x 9376 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_corpus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At then end of this section, our data set is extremely high dimensional. In a next iteration of our project, we wish to explore PCA to dimensionally reduce the data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "After we pre-process our data and split it into our test and training set, we can now train our models. We, for our purposes, analyse three different models - Logistic Regression, Naïve Bayes and K-Nearest Neighbor. Two out of these three models are parametric models and one out of these three models is non-parametric. By selecting both kinds of models, we are able to analyze which of these kinds also works the best for text classification.\n",
    "## Logistic Regression\n",
    "(http://cs229.stanford.edu/notes/cs229-notes1.pdf)  \n",
    "Logistic regression is a classification model that fits a sigmoid function on a linear regression model to obtain the probability of a sample belonging to a class and classifies test samples in this manner. First, we train our logistic regression model on the unbalanced data set and then we train on our SMOTE'd data set and test both on the test data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(training_corpus, training_label)\n",
    "labels = lr.predict(test_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X, y.values.ravel())\n",
    "labels_sm = lr.predict(test_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naïve Bayes\n",
    "Gausian Naïve Bayes is a parametric classifier model. It takes the samples and predicts continuous multidimensional Gaussian distributions for each class. It then predicts the class of a test sample based on the conditional probability of the sample belonging to a distribution. It utilizes Bayes theorem to classify data samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = GaussianNB()\n",
    "nb.fit(training_corpus, training_label)\n",
    "labels2 = nb.predict(test_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = GaussianNB()\n",
    "nb.fit(X, y.values.ravel())\n",
    "labels2_sm = nb.predict(test_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train our Gaussian Naïve Bayes model on our SMOTE'd data for further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Nearest Neighbor\n",
    "(https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.DistanceMetric.html)  \n",
    "\n",
    "Out of all three classifier mdoels that we are using to build our spam classifier, K-Nearest Neighbor is the only non-parametric classifier. What this means is that KNN does not derive any parameters from the data set to classify samples unlike Logistic Regression or Naïve Bayes. \n",
    "K-Nearest neighbor algorithm works by classifying a test sample the same classes as its nearest K-neighbors. To analyze how well the algorithm works for our spam classifier, we will be using four distance measures:\n",
    "- Chebyshev distance: max(|x - y|)\n",
    "- Manhattan distance: sum(|x - y|)\n",
    "- Euclidean distance: sqrt(sum((x - y)^2))  \n",
    "\n",
    "These distance measures are used to find the K-nearest neighbors. This can change our final metrics since we are varying the closest neighbors of a sample. We set the K-value to 5 as a default for all models. In a seperate experiment, we would like to experiment with different K values as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='euclidean',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_cheb = KNeighborsClassifier(n_neighbors = 5, metric='chebyshev')\n",
    "knn_man = KNeighborsClassifier(n_neighbors = 5, metric='manhattan')\n",
    "knn_euc = KNeighborsClassifier(n_neighbors = 5, metric='euclidean')\n",
    "knn_cheb.fit(training_corpus, training_label)\n",
    "knn_man.fit(training_corpus, training_label)\n",
    "knn_euc.fit(training_corpus, training_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels3_man = knn_man.predict(test_corpus)\n",
    "labels3_cheb = knn_cheb.predict(test_corpus)\n",
    "labels3_euc = knn_euc.predict(test_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the two code blocks above, we fit our models on our unbalanced training data set and predict values for our test data sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE\n",
    "Now, we will train our models on our balanced training data set and predict value on our test data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='euclidean',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_cheb.fit(X, y.values.ravel())\n",
    "knn_man.fit(X, y.values.ravel())\n",
    "knn_euc.fit(X, y.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels3_man_sm = knn_man.predict(test_corpus)\n",
    "labels3_cheb_sm = knn_cheb.predict(test_corpus)\n",
    "labels3_euc_sm = knn_euc.predict(test_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we have all of our different classification models trained, we move onto our analysis section to analyze all of our different metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "This section is for analyzing our metrics for the different models and compare them. For each of our model,we obtain the confusion matrix and observe the overall accuracy of our test data set and the precision, recall score for our two classes which are ham and spam. \n",
    "For our spam classifier, we care more about our precision score and recall score for ham class. For a spam classifier, it is imperative that we do not put ham messages that are not spam into the spam folder or completely block them. The recall score measures how many of our non-spam messages are classified correctly and precision measures how many of our non-spam messages are actually classified as non-spam. We will be measuring the precision and recall of our spam class as well to compare."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Resgression\n",
    "First, we observe metrics of our logistic regression classifier model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[971,   0],\n",
       "       [ 51,  93]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(test_label, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        ham     0.9501    1.0000    0.9744       971\n",
      "       spam     1.0000    0.6458    0.7848       144\n",
      "\n",
      "avg / total     0.9565    0.9543    0.9499      1115\n",
      "\n",
      "Accuracy is =  0.9542600896860987\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(test_label, labels, digits=4))\n",
    "print(\"Accuracy is = \", metrics.accuracy_score(test_label, labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we observe from the confusion metrics first is that there are 1115 records in our test class, 944 of which are ham and 171 of which are spam. We observe that our accuracy is ~ 0.95 which seems optimal. A precision socre of 0.94 for ham indicated that 94 percent of predicted ham messges are ham and the remaining 6 percent are spam. Thus, when we implement our spam filter, only 6 percent of our predicted non spam messages would be faulty. A recall score of 0.99 indicated that almost all non-spam messages are unblocked which is optimal to maintain a minimal loss of information. The low recall score for spam class can be attributed to the fact that we trained our model on an unbalaned training set which will cause a level of inability in our model to classify the minority class - \"spam\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[961,  10],\n",
       "       [ 18, 126]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(test_label, labels_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        ham     0.9816    0.9897    0.9856       971\n",
      "       spam     0.9265    0.8750    0.9000       144\n",
      "\n",
      "avg / total     0.9745    0.9749    0.9746      1115\n",
      "\n",
      "Accuracy is =  0.9748878923766816\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(test_label, labels_sm, digits=4))\n",
    "print(\"Accuracy is = \", metrics.accuracy_score(test_label, labels_sm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we compare our balanced model against our unbalanced model, we see that there is a 0.03 increase in accuracy which suggests that balancing the training data set improved our spam filter. By oversampling the minority class, we improve weights for each term in the set of texts. There is a strong increase of 0.25 in our recall score for spam class. This indicates that a significant portion of spams are correctly recognized by our spam filter. \n",
    "Because logistic regression is a paramteric classification model, it derives a set of parameters (weights for each dimension or term) that it uses to classify texts. As we balance our training data set, the model gets a better estimate for all the terms that belong to the spam class and that causes an increase in recall score for spam class. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naïve Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[856, 115],\n",
       "       [ 11, 133]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(test_label, labels2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        ham     0.9873    0.8816    0.9314       971\n",
      "       spam     0.5363    0.9236    0.6786       144\n",
      "\n",
      "avg / total     0.9291    0.8870    0.8988      1115\n",
      "\n",
      "Accuracy is =  0.8869955156950673\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(test_label, labels2, digits=4))\n",
    "print(\"Accuracy is = \", metrics.accuracy_score(test_label, labels2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right away, we observe a lower accuracy score and a lower recall score for ham class. This indicates that a higher portion of our non-spam messages are blocked by our filter and are classified as false negatives. This is not optimal for a spam filter as blocking non spam messages is a significant loss. This is also reflected in the low precision socre for spam class as almost half of the messages that are blocked are non-spam. \n",
    "For pure conjecture, we can suggest that this happens because of we are using a Gaussian distribution to classify. If we use a multinomial or bernoulli distrbution then we might see different results which is reflected in other works done on this (http://www2.aueb.gr/users/ion/docs/ceas2006_paper.pdf). In a multinomial event model, each term occurence is modelled as a discreet event instead of predicting a continuous distribution which makes a better classifier model for our spam classifier. In the nexxt iteration, this would be something we would wish to explore further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[856, 115],\n",
       "       [ 11, 133]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(test_label, labels2_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        ham     0.9873    0.8816    0.9314       971\n",
      "       spam     0.5363    0.9236    0.6786       144\n",
      "\n",
      "avg / total     0.9291    0.8870    0.8988      1115\n",
      "\n",
      "Accuracy is =  0.8869955156950673\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(test_label, labels2_sm, digits=4))\n",
    "print(\"Accuracy is = \", metrics.accuracy_score(test_label, labels2_sm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do not observe a difference in our metrics after we balance classes which indicates changing the sample size for the classes does not chance the parameters of the guassian distribution. \n",
    "Like we said in the last section, modeling a different Naïve Bayes model will possibly improve our spam filter model. In a future iteration of this project, we would like to explore that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbor\n",
    "After observing both of the parametric classifier models, we now observe K-Nearest neighbor and metrics outputted from that. First, we analyze KNN model on our un-balanced training data set. Since KNN is a non-parametric model, we can hypothesize that we will see a high uprise in metrics after we test on our balanced training model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chebyshev distance\n",
    "Chebyshev distance is measured by finding the maximum distance between two terms out of all the terms common between the two texts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[933,  38],\n",
       "       [ 83,  61]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(test_label, labels3_cheb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        ham     0.9183    0.9609    0.9391       971\n",
      "       spam     0.6162    0.4236    0.5021       144\n",
      "\n",
      "avg / total     0.8793    0.8915    0.8827      1115\n",
      "\n",
      "Accuracy is =  0.8914798206278027\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(test_label, labels3_cheb, digits=4))\n",
    "print(\"Accuracy is = \", metrics.accuracy_score(test_label, labels3_cheb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right away, we observe a lower accuracy that both of our parametric models which is a clear indication of how having an unbalanced data set impacts our model. A low precision and recall value for the spam class is because the training set does not have as many spam samples. We still obtain a high recall and precision for ham messages. Out of our unblocked messages, 89 percent are ham messages and 88 percent of our ham messages are relayed. However, more than 50 percent of our spam messages are misclassified. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manhattan distance\n",
    "Manhattan distance is taken by summing the distance between all of the terms between the two documents. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[971,   0],\n",
       "       [103,  41]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(test_label, labels3_man)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        ham     0.9041    1.0000    0.9496       971\n",
      "       spam     1.0000    0.2847    0.4432       144\n",
      "\n",
      "avg / total     0.9165    0.9076    0.8842      1115\n",
      "\n",
      "Accuracy is =  0.9076233183856502\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(test_label, labels3_man, digits=4))\n",
    "print(\"Accuracy is = \", metrics.accuracy_score(test_label, labels3_man))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe a better accuracy when we measure similarity through Manhattan distance but we also observe an extremely low recall value for recall for spam class. This is because 125 of spam messages are not caught by the spam filter and are misclassified. We see a 100 percent precision for spams and recall for hams which indicates that none of actual ham messages are misclassified as spam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Euclidean distance\n",
    "Euclidean distance measure is the same as Manhattan except distance is calculated in a 2-norm space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[971,   0],\n",
       "       [104,  40]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(test_label, labels3_euc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        ham     0.9033    1.0000    0.9492       971\n",
      "       spam     1.0000    0.2778    0.4348       144\n",
      "\n",
      "avg / total     0.9158    0.9067    0.8827      1115\n",
      "\n",
      "Accuracy is =  0.9067264573991032\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(test_label, labels3_euc, digits=4))\n",
    "print(\"Accuracy is = \", metrics.accuracy_score(test_label, labels3_euc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see metrics almost the same as Manhattan which is an indication of the similarity between the ways distance is calculated between two different samples.\n",
    "\n",
    "Throughout all of our different KNN models, we see a consistent decrease in the precision and recall values for spam class. This is a direct result of training our models on an unbalanced data set. Because we have a major class and a minor class in our training data set, our model has a strong bias towards the majority class. Thus, more than half of spam samples are misclassified. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE\n",
    "We also trained our KNN models on balanced training models and we can analyze if our hypothesis was correct and we see an increase in the accuracy and precision and recall from the test results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chebyshev distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[901,  70],\n",
       "       [ 69,  75]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(test_label, labels3_cheb_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        ham     0.9289    0.9279    0.9284       971\n",
      "       spam     0.5172    0.5208    0.5190       144\n",
      "\n",
      "avg / total     0.8757    0.8753    0.8755      1115\n",
      "\n",
      "Accuracy is =  0.8753363228699551\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(test_label, labels3_cheb_sm, digits=4))\n",
    "print(\"Accuracy is = \", metrics.accuracy_score(test_label, labels3_cheb_sm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see an increase in the recall scores for our model here as well but not as large as for Manhattan distance which might be a result of the fact that Chebyshev distance measures the maximum distance between two term tf-idf values which does not account for other words. This indicates that Chebyshev might be a poor distance measure for, measuring similarity between texts regardless. We still observe an increase in the accuracy score of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manhattan distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[971,   0],\n",
       "       [ 52,  92]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(test_label, labels3_man_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        ham     0.9492    1.0000    0.9739       971\n",
      "       spam     1.0000    0.6389    0.7797       144\n",
      "\n",
      "avg / total     0.9557    0.9534    0.9488      1115\n",
      "\n",
      "Accuracy is =  0.9533632286995516\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(test_label, labels3_man_sm, digits=4))\n",
    "print(\"Accuracy is = \", metrics.accuracy_score(test_label, labels3_man_sm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see a significant increase of in the recall value for spam class and the precision value for ham class. This indicated that after we balanced our training data, our model now has a stronger capability to distniguish which samples are spam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[970,   1],\n",
       "       [ 46,  98]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(test_label, labels3_euc_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        ham     0.9547    0.9990    0.9763       971\n",
      "       spam     0.9899    0.6806    0.8066       144\n",
      "\n",
      "avg / total     0.9593    0.9578    0.9544      1115\n",
      "\n",
      "Accuracy is =  0.957847533632287\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(test_label, labels3_euc_sm, digits=4))\n",
    "print(\"Accuracy is = \", metrics.accuracy_score(test_label, labels3_euc_sm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the significant increase in the accuracy score, we also observe an increase in the recall value for spam. A good hundred percent of our ham messages make it through the filter and 94 percent of our ham messages are true ham messages. That is acceptable for our model. However, 33 percent of spam messages make it past the filter and are misclassified as ham messages.\n",
    "\n",
    "From the metrics that we obtained from all of our models, we see that accuracy score increases by a lot for KNN when the data is balanced. \n",
    "\n",
    "## Comparison of metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_x = [metrics.precision_score(test_label, labels, pos_label=\"ham\"),\n",
    "         metrics.precision_score(test_label, labels_sm, pos_label=\"ham\"),\n",
    "         metrics.precision_score(test_label, labels2, pos_label=\"ham\"),\n",
    "         metrics.precision_score(test_label, labels2_sm, pos_label=\"ham\"),\n",
    "         metrics.precision_score(test_label, labels3_cheb, pos_label=\"ham\"),\n",
    "         metrics.precision_score(test_label, labels3_cheb_sm, pos_label=\"ham\"),\n",
    "         metrics.precision_score(test_label, labels3_euc, pos_label=\"ham\"),\n",
    "         metrics.precision_score(test_label, labels3_euc_sm, pos_label=\"ham\"),\n",
    "         metrics.precision_score(test_label, labels3_man, pos_label=\"ham\"),\n",
    "         metrics.precision_score(test_label, labels3_man_sm, pos_label=\"ham\")]\n",
    "\n",
    "data_y = [metrics.recall_score(test_label, labels, pos_label=\"ham\"),\n",
    "         metrics.recall_score(test_label, labels_sm, pos_label=\"ham\"),\n",
    "         metrics.recall_score(test_label, labels2, pos_label=\"ham\"),\n",
    "         metrics.recall_score(test_label, labels2_sm, pos_label=\"ham\"),\n",
    "         metrics.recall_score(test_label, labels3_cheb, pos_label=\"ham\"),\n",
    "         metrics.recall_score(test_label, labels3_cheb_sm, pos_label=\"ham\"),\n",
    "         metrics.recall_score(test_label, labels3_euc, pos_label=\"ham\"),\n",
    "         metrics.recall_score(test_label, labels3_euc_sm, pos_label=\"ham\"),\n",
    "         metrics.recall_score(test_label, labels3_man, pos_label=\"ham\"),\n",
    "         metrics.recall_score(test_label, labels3_man_sm, pos_label=\"ham\")]\n",
    "\n",
    "colors = np.random.rand(10)\n",
    "n = [1,2,3,4,5,6,7,8,9,0]\n",
    "fig, ax = plt.subplots()\n",
    "area = [500 * value for value in data_x]\n",
    "ax.scatter(data_x, data_y, c=colors, s = area ,alpha=0.5)\n",
    "ax.set_xlabel(\"Ham Precision Score\")\n",
    "ax.set_ylabel(\"Ham Recall Score\")\n",
    "label = [\"logR\", \"logR_SMOTE\", \"GNB\", \"GNB_SMOTE\",\n",
    "          \"KNN_Cheby\", \"KNN_Cheby_SMOTE\", \"KNN_Euc\", \"KNN_Euc_SMOTE\", \"KNN_Man\", \"KNN_Man_SMOTE\"]\n",
    "c = 0\n",
    "for i in label:\n",
    "    ax.annotate(i, (data_x[c], data_y[c]))\n",
    "    c = c + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we plot the precision score and recall score for all of our models, we see that logistic regression performs the best since it has the best combination of the two after we train it on our SMOTE data. All the KNN models except for those calculated with the Chebyshev distance have a 100 percent recall when we train them on SMOTE data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_x = [metrics.precision_score(test_label, labels, pos_label=\"spam\"),\n",
    "         metrics.precision_score(test_label, labels_sm, pos_label=\"spam\"),\n",
    "         metrics.precision_score(test_label, labels2, pos_label=\"spam\"),\n",
    "         metrics.precision_score(test_label, labels2_sm, pos_label=\"spam\"),\n",
    "         metrics.precision_score(test_label, labels3_cheb, pos_label=\"spam\"),\n",
    "         metrics.precision_score(test_label, labels3_cheb_sm, pos_label=\"spam\"),\n",
    "         metrics.precision_score(test_label, labels3_euc, pos_label=\"spam\"),\n",
    "         metrics.precision_score(test_label, labels3_euc_sm, pos_label=\"spam\"),\n",
    "         metrics.precision_score(test_label, labels3_man, pos_label=\"spam\"),\n",
    "         metrics.precision_score(test_label, labels3_man_sm, pos_label=\"spam\")]\n",
    "\n",
    "data_y = [metrics.recall_score(test_label, labels, pos_label=\"spam\"),\n",
    "         metrics.recall_score(test_label, labels_sm, pos_label=\"spam\"),\n",
    "         metrics.recall_score(test_label, labels2, pos_label=\"spam\"),\n",
    "         metrics.recall_score(test_label, labels2_sm, pos_label=\"spam\"),\n",
    "         metrics.recall_score(test_label, labels3_cheb, pos_label=\"spam\"),\n",
    "         metrics.recall_score(test_label, labels3_cheb_sm, pos_label=\"spam\"),\n",
    "         metrics.recall_score(test_label, labels3_euc, pos_label=\"spam\"),\n",
    "         metrics.recall_score(test_label, labels3_euc_sm, pos_label=\"spam\"),\n",
    "         metrics.recall_score(test_label, labels3_man, pos_label=\"spam\"),\n",
    "         metrics.recall_score(test_label, labels3_man_sm, pos_label=\"spam\")]\n",
    "\n",
    "colors = np.random.rand(10)\n",
    "n = [1,2,3,4,5,6,7,8,9,0]\n",
    "fig, ax = plt.subplots()\n",
    "area = [500 * value for value in data_x]\n",
    "ax.scatter(data_x, data_y, c=colors, s = area ,alpha=0.5)\n",
    "ax.set_xlabel(\"Spam Precision Score\")\n",
    "ax.set_ylabel(\"Spam Recall Score\")\n",
    "label = [\"logR\", \"logR_SMOTE\", \"GNB\", \"GNB_SMOTE\",\n",
    "          \"KNN_Cheby\", \"KNN_Cheby_SMOTE\", \"KNN_Euc\", \"KNN_Euc_SMOTE\", \"KNN_Man\", \"KNN_Man_SMOTE\"]\n",
    "c = 0\n",
    "for i in label:\n",
    "    ax.annotate(i, (data_x[c], data_y[c]))\n",
    "    c = c + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From our plots for precision and recall for spam class, we observe that Logistic Regression perfomrs better than all models if we think about it in terms of a combination of the two. The logistic regression model that is trained on an unbalanced data set and majortiy of the KNN models bar the Chebyshev distance KNN model all have a good spam precision score but have a low spam recall score. Similarly, Gaussian Naïve Bayes models and KNN models with a Chebyshev distance mesaure has a higher spam recall score but a lower spam recall score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By running our analysis, we observe the following:\n",
    "- TF-IDF matrix is a sparse matrix\n",
    "- Logisitc regression model performs optimally with an unbalanced training data set but performs better with a balanced training data set. We obtained a high positive precision and recall score. \n",
    "- Gaussian Naïve Bayes is not the most optimal Naïve Bayes algorithm to use for building a spam filter because it derives a continuous Gaussian distribution instead of a discreet distribution like Multinomial or Bernoulli. We observe a lowe rpositive recall score which is not optimal.\n",
    "- KNN, being a non-parametric model performs better with a more balanced training data set and Chebyshev distance is not optimal to use as a distance measure for our K-Nearest NEighbor model.\n",
    "\n",
    "## Future Iteration\n",
    "For furture iterations, we would like to explore the following analyses:\n",
    "- Explore stemming our messages and see how that affects performance of models\n",
    "- Reduce the dimensionality of the TF-IDF matrix by implementing dimensionality reduction techniques such as PCA to see if noise is reduced\n",
    "- Explore other N-gram ranges for our TF-IDf matrix\n",
    "- Explore Multinomial or Bernoulli Naïve Bayes models\n",
    "- Explore different K-values for KNN across different distance measures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> References: </h3>\n",
    "1. To train our models, we use a spam SMS collection data set obtained from https://www.kaggle.com/uciml/sms-spam-collection-dataset/home, https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection\n",
    "2. For documentation of distance metrics https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.DistanceMetric.html\n",
    "3. Metrics explanation: https://developers.google.com/machine-learning/crash-course/classification/precision-and-recall\n",
    "4. Naïve Bayes analysis: http://www2.aueb.gr/users/ion/docs/ceas2006_paper.pdf\n",
    "5. Information about TF-IDF: https://www.elephate.com/blog/what-is-tf-idf/\n",
    "6. Information about Logistic Regression: http://cs229.stanford.edu/notes/cs229-notes1.pdf\n",
    "7. Used as coding reference: http://nbviewer.jupyter.org/github/andressotov/News-Categorization-MNB/blob/master/News_Categorization_MNB%2010-oct-2017.ipynb\n",
    "8. Used for refering to usages: https://www.kaggle.com/madpiano/spam-sms-classification-using-knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
